{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "         category                                              title  \\\n",
      "0  ARTS & CULTURE  Modeling Agencies Enabled Sexual Predators For...   \n",
      "1  ARTS & CULTURE  Actor Jeff Hiller Talks “Bright Colors And Bol...   \n",
      "2  ARTS & CULTURE  New Yorker Cover Puts Trump 'In The Hole' Afte...   \n",
      "3  ARTS & CULTURE  Man Surprises Girlfriend By Drawing Them In Di...   \n",
      "4  ARTS & CULTURE  This Artist Gives Renaissance-Style Sculptures...   \n",
      "\n",
      "                                                body Unnamed: 3 Unnamed: 4  \\\n",
      "0  In October 2017, Carolyn Kramer received a dis...        NaN        NaN   \n",
      "1  This week I talked with actor Jeff Hiller abou...        NaN        NaN   \n",
      "2  The New Yorker is taking on President Donald T...        NaN        NaN   \n",
      "3  Kellen Hickey, a 26-year-old who lives in Huds...        NaN        NaN   \n",
      "4  There’s something about combining the traditio...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ... Unnamed: 315  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN  ...          NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN  ...          NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN  ...          NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN  ...          NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN  ...          NaN   \n",
      "\n",
      "  Unnamed: 316 Unnamed: 317 Unnamed: 318 Unnamed: 319 Unnamed: 320  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "  Unnamed: 321 Unnamed: 322 Unnamed: 323 Unnamed: 324  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 325 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zobayer\\AppData\\Local\\Temp\\ipykernel_13196\\4053713827.py:3: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Loading the news article dataset\n",
    "file_path = 'news-article-categories clean.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Combine 'title' and 'body' columns into a single 'text' column\n",
    "data['text'] = data['title'] + \" \" + data['body']\n",
    "data = data.dropna(subset=['text', 'category'])  # Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Divide the data into training and testing sets\n",
    "X = data['text']  \n",
    "y= data['category']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the text data using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores (Initial Model): [0.80454545 0.80363636 0.77707006 0.78798908 0.80345769]\n",
      "Mean Accuracy (Initial Model): 0.7953\n",
      "Standard Deviation (Initial Model): 0.0110\n",
      "\n",
      "Initial Model Evaluation Metrics:\n",
      "Accuracy: 81.31%\n",
      "Precision: 81.34%\n",
      "Recall: 81.31%\n",
      "F1 Score: 81.21%\n",
      "\n",
      "Classification Report (Initial Model):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.84      0.89      0.87       205\n",
      "      BUSINESS       0.74      0.76      0.75       114\n",
      "        COMEDY       0.75      0.88      0.81        74\n",
      "         CRIME       0.84      0.81      0.82        57\n",
      "     EDUCATION       0.86      0.88      0.87       108\n",
      " ENTERTAINMENT       0.82      0.75      0.78       100\n",
      "   ENVIRONMENT       0.85      0.85      0.85        97\n",
      "         MEDIA       0.84      0.72      0.77        67\n",
      "      POLITICS       0.75      0.77      0.76       103\n",
      "      RELIGION       0.86      0.83      0.84       101\n",
      "       SCIENCE       0.77      0.81      0.79        54\n",
      "        SPORTS       0.90      0.93      0.91       101\n",
      "          TECH       0.80      0.69      0.74        85\n",
      "         WOMEN       0.75      0.71      0.73       109\n",
      "\n",
      "      accuracy                           0.81      1375\n",
      "     macro avg       0.81      0.81      0.81      1375\n",
      "  weighted avg       0.81      0.81      0.81      1375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: making the first SVM model with default settings\n",
    "initial_model = SVC(kernel='linear', random_state=42)  # Default parameters\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores_initial = cross_val_score(initial_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results for the initial model\n",
    "print(f\"Cross-Validation Accuracy Scores (Initial Model): {cv_scores_initial}\")\n",
    "print(f\"Mean Accuracy (Initial Model): {cv_scores_initial.mean():.4f}\")\n",
    "print(f\"Standard Deviation (Initial Model): {cv_scores_initial.std():.4f}\")\n",
    "\n",
    "# Train the initial model on the full training data\n",
    "initial_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Test the initial model using the test data\n",
    "y_pred_initial = initial_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the performance measures for the initial model\n",
    "accuracy_initial = accuracy_score(y_test, y_pred_initial)\n",
    "precision_initial = precision_score(y_test, y_pred_initial, average='weighted')\n",
    "recall_initial = recall_score(y_test, y_pred_initial, average='weighted')\n",
    "f1_initial = f1_score(y_test, y_pred_initial, average='weighted')\n",
    "\n",
    "# Display the performance measures for the initial model\n",
    "print(\"\\nInitial Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_initial * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_initial * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_initial * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_initial * 100:.2f}%\")\n",
    "\n",
    "# Print classification report for the initial model\n",
    "print(\"\\nClassification Report (Initial Model):\\n\", classification_report(y_test, y_pred_initial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best Parameters from GridSearch: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Cross-Validation Accuracy Scores (Optimized Model): [0.80545455 0.80272727 0.78434941 0.78252957 0.80800728]\n",
      "Mean Accuracy (Optimized Model): 0.7966\n",
      "Standard Deviation (Optimized Model): 0.0109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: applying Hyperparameter Tuning with GridSearchCV\n",
    "# Definining the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Perform GridSearch for best parameters\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"\\nBest Parameters from GridSearch:\", grid_search.best_params_)\n",
    "\n",
    "# Save the best model from GridSearchCV \n",
    "best_model= grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation with the model after the hyperparameter tuning(optimised model)\n",
    "cv_scores_optimized = cross_val_score(best_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results for the optimized model\n",
    "print(f\"\\nCross-Validation Accuracy Scores (Optimized Model): {cv_scores_optimized}\")\n",
    "print(f\"Mean Accuracy (Optimized Model): {cv_scores_optimized.mean():.4f}\")\n",
    "print(f\"Standard Deviation (Optimized Model): {cv_scores_optimized.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Model Evaluation Metrics:\n",
      "Accuracy: 81.82%\n",
      "Precision: 81.94%\n",
      "Recall: 81.82%\n",
      "F1 Score: 81.75%\n",
      "\n",
      "Classification Report (Optimized Model):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.83      0.90      0.86       205\n",
      "      BUSINESS       0.80      0.73      0.76       114\n",
      "        COMEDY       0.75      0.88      0.81        74\n",
      "         CRIME       0.80      0.82      0.81        57\n",
      "     EDUCATION       0.87      0.90      0.88       108\n",
      " ENTERTAINMENT       0.81      0.78      0.80       100\n",
      "   ENVIRONMENT       0.85      0.82      0.84        97\n",
      "         MEDIA       0.84      0.72      0.77        67\n",
      "      POLITICS       0.73      0.80      0.76       103\n",
      "      RELIGION       0.88      0.81      0.85       101\n",
      "       SCIENCE       0.75      0.78      0.76        54\n",
      "        SPORTS       0.92      0.92      0.92       101\n",
      "          TECH       0.79      0.75      0.77        85\n",
      "         WOMEN       0.79      0.72      0.76       109\n",
      "\n",
      "      accuracy                           0.82      1375\n",
      "     macro avg       0.81      0.81      0.81      1375\n",
      "  weighted avg       0.82      0.82      0.82      1375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Evaluate the  SVM Model after the hyperparameter tuning\n",
    "\n",
    "# Evaluate the  model on the test set\n",
    "y_pred_optimized = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the performance measures for the optimized model\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "optimized_precision = precision_score(y_test, y_pred_optimized, average='weighted')\n",
    "optimized_recall = recall_score(y_test, y_pred_optimized, average='weighted')\n",
    "optimized_f1 = f1_score(y_test, y_pred_optimized, average='weighted')\n",
    "\n",
    "# Display the performance for the optimized model\n",
    "print(\"\\nOptimized Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {optimized_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision:{optimized_precision * 100:.2f}%\")\n",
    "print(f\"Recall: {optimized_recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {optimized_f1 * 100:.2f}%\")\n",
    "\n",
    "# Print the classification report for the optimized model\n",
    "print(\"\\nClassification Report (Optimized Model):\\n\", classification_report(y_test, y_pred_optimized))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to C:\\Users\\mahamat ali\\AppData\\Roaming\\nltk_data\\corpora\\names\\svm_gridsearch_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Saving the results to a CSV file\n",
    "output_file = r\"C:\\Users\\mahamat ali\\AppData\\Roaming\\nltk_data\\corpora\\names\\svm_gridsearch_results.csv\"\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Initial_Predicted': y_pred_initial,\n",
    "    'Optimized_Predicted': y_pred_optimized,\n",
    "    'Initial_CV_Mean_Accuracy':[cv_scores_initial.mean()] * len(y_test),\n",
    "'Optimized_CV_Mean_Accuracy': [cv_scores_optimized.mean()] * len(y_test)\n",
    "\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
